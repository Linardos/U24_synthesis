# U24Â Breastâ€‘CancerÂ SynthesisÂ &Â Classification

A reproducible research framework for **training, evaluating, and analysing diffusionâ€‘based synthetic mammography data** and its impact on breastâ€‘cancer classification.

The project offers:

* endâ€‘toâ€‘end **data handling** for public (DDSM, InBreast, CMMD, etc.) and private datasets;
* scalable **training pipelines** in vanilla PyTorch *and* PyTorchâ€¯Lightning;
* utilities to **blend real & synthetic samples** with precise classâ€‘balance control;
* readyâ€‘made **evaluation & visualisation** scripts for AUC, balanced accuracy, sensitivity/specificity, and FID;
* a **tmux launcher** that runs five random seeds in parallel.

---

## Directory layout

```
linardosâ€‘u24_synthesis/
â”œâ”€â”€ config.yaml                # simple classifier config (PyTorch)
â”œâ”€â”€ data_loaders.py            # core Dataset + real/synthetic mixer
â”œâ”€â”€ holdout_train.py           # single holdâ€‘out split training script
â”œâ”€â”€ main.py                    # kâ€‘fold CV trainer (default)
â”œâ”€â”€ models.py                  # backbone factory (ResNet, DenseNet, â€¦)
â”œâ”€â”€ requirements.txt           # Python deps
â”œâ”€â”€ tmux_initiate_fiveseeds.sh # convenience launcher
â”œâ”€â”€ trim_synthetic.py          # downâ€‘sample synthetic folders per class
â”œâ”€â”€ read_metrics.py            # quick CSV/PKL reader
â”‚
â”œâ”€â”€ basic_trials/              # minimal UNet + GAN baselines (PL)
â”œâ”€â”€ data_handling/             # datasetâ€‘specific preprocessing helpers
â”œâ”€â”€ lightning_synthesis/       # full diffusion/GAN training workflows (PL)
â”œâ”€â”€ plots_for_paper/           # reusable plotting scripts
â””â”€â”€ utils/                     # misc helpers
```

---

## Quickâ€‘start (conda)

1. **Create & activate** a fresh environment (PythonÂ 3.9 recommended)

   ```bash
   conda create -n U24 python=3.12 -y
   conda activate U24 
   ```

2. **Install PyTorch** with CUDA *or* CPU only (choose the line that matches your system)

   ```bash
   # CUDAÂ 12.1 (find the one for your version though
   pip install torch==2.6.0 torchvision==0.21.0 --index-url https://download.pytorch.org/whl/cu121

   ```

3. **Install project requirements**

   ```bash
   pip install -r requirements.txt
   ```

   > ðŸ’¡  `xformers` wheels are preâ€‘built for common CUDA versions. If installation fails, remove it from
   > `requirements.txt` and skip flashâ€‘attention features.

4. **(Optional) Jupyter support**

   ```bash
   pip install jupyterlab
   ```

---

## Data preparation

All training scripts expect a directory hierarchy such as

```
ROOT/
 â”œâ”€â”€ original/               # real NIfTI files organised by class
 â”‚     â”œâ”€â”€ benign/
 â”‚     â””â”€â”€ malignant/
 â””â”€â”€ synthetic_guide8.0/     # CFGâ€‘DDPM outputs (same subâ€‘folder layout)
```

Preâ€‘processing helpers for each public dataset live under `data_handling/`.  Edit
`config.yaml â†’ root_dir` to point at your *train* split.

---

## Training recipes

### 1. Fiveâ€‘fold crossâ€‘validation (default)

```bash
python main.py         # uses seed from config.yaml
python main.py 123     # override random seed
```

Key options are centralised in **`config.yaml`**:

| Field             | Purpose                                                   |
| ----------------- | --------------------------------------------------------- |
| `real_percentage` | Fraction of real samples in the mixed training set (0â€“1). |
| `num_classes`     | 2Â (binary)Â Â·Â 3Â Â·Â 4â€‘class setups supported.                |
| `model_name`      | `resnet50`, `densenet121`, `efficientnet_b0`, â€¦           |
| `k_folds`         | 0 â†’ holdâ€‘out; â‰¥2 â†’ kâ€‘fold CV.                             |

### 2. Holdâ€‘out split

```bash
python holdout_train.py
```

### 3. Launch 5 seeds in tmux

```bash
bash tmux_initiate_fiveseeds.sh 01  # creates session U24_session_01
```

---

## License & citation

Forthcoming
---

