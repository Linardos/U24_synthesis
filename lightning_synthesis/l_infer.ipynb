{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67dfb355-66f9-46e4-9054-a6600a0a7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from data_loaders_l import SynthesisDataModule\n",
    "from model_architectures import DDPM\n",
    "\n",
    "# Load configuration\n",
    "with open('config_l.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Extract parameters from config\n",
    "batch_size = config.get('batch_size', 1)  # use a small batch size for inference\n",
    "latent_dim = config.get('latent_dim', 100)\n",
    "label_dim = config.get('label_dim', 4)\n",
    "experiment_name = config.get('experiment_name', 'default_experiment')\n",
    "model_dir = config.get('model_dir', 'saved_models')\n",
    "\n",
    "# Specify the checkpoint path to load the trained model from.\n",
    "# checkpoint_path = os.path.join(model_dir, 'ddpm-epoch=30-train_loss=0.1432.ckpt')\n",
    "checkpoint_path = os.path.join(model_dir, 'ddpm-epoch=30-train_loss=0.1432.ckpt')\n",
    "\n",
    "# Set up the same transform as used during training\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: (x - x.min()) / (x.max() - x.min() + 1e-8)), \n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "    transforms.Lambda(lambda x: x.to(torch.float32))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a207f74d-98a8-46ae-b26a-c69424e2df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data module for inference\n",
    "data_module = SynthesisDataModule(batch_size=batch_size, transform=transform)\n",
    "data_module.setup()\n",
    "\n",
    "# Load the trained model from checkpoint\n",
    "model = DDPM.load_from_checkpoint(\n",
    "    checkpoint_path,\n",
    "    label_dim=label_dim,\n",
    "    learning_rate=0  # learning_rate is not used during inference\n",
    ")\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Move model to the right device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Create a directory to save inference results\n",
    "inference_dir = os.path.join('inference_results', experiment_name)\n",
    "os.makedirs(inference_dir, exist_ok=True)\n",
    "\n",
    "# Choose dataloader\n",
    "if hasattr(data_module, 'test_dataloader'):\n",
    "    dataloader = data_module.test_dataloader()\n",
    "else:\n",
    "    dataloader = data_module.val_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a4b6bc-027d-4bdc-b653-009b250bc93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Determine the device the model is on\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "num_images_to_generate = 10  # How many images you want to generate\n",
    "num_timesteps = model.timesteps  # Number of denoising steps\n",
    "\n",
    "# Function to generate images using DDPM\n",
    "def sample_ddpm(model, num_samples, num_timesteps, label=None):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    img_size = (num_samples, 1, 256, 256)  # Assuming grayscale 256x256 images\n",
    "    noisy_img = torch.randn(img_size, device=device)\n",
    "\n",
    "    if label is not None:\n",
    "        label_tensor = torch.full((num_samples,), label, dtype=torch.long, device=device)\n",
    "    else:\n",
    "        label_tensor = None\n",
    "\n",
    "    for t in reversed(range(num_timesteps)):\n",
    "        timestep_tensor = torch.tensor([t] * num_samples, dtype=torch.long, device=device)\n",
    "        predicted_noise = model(noisy_img, timestep_tensor, label_tensor)\n",
    "\n",
    "        alpha_t = model.alpha_hat[t].to(device)\n",
    "        sqrt_alpha_t = torch.sqrt(alpha_t)\n",
    "        sqrt_one_minus_alpha_t = torch.sqrt(1 - alpha_t)\n",
    "\n",
    "        # Fix: Add correct noise scaling\n",
    "        if t > 0:\n",
    "            sigma_t = torch.sqrt((1 - alpha_t) / (1 - model.alpha_hat[t-1]))\n",
    "            noise = torch.randn_like(noisy_img, device=device) * sigma_t\n",
    "            noisy_img = (1 / sqrt_alpha_t) * (noisy_img - sqrt_one_minus_alpha_t * predicted_noise) + noise\n",
    "        else:\n",
    "            noisy_img = (1 / sqrt_alpha_t) * (noisy_img - sqrt_one_minus_alpha_t * predicted_noise)\n",
    "\n",
    "    return torch.clamp(noisy_img, -1, 1)  # Ensure final values are in range\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94e4829-601e-4b1d-ad48-9426c4e8f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure inline plotting works in JupyterLab\n",
    "%matplotlib inline  \n",
    "\n",
    "# Generate images\n",
    "generated_images = sample_ddpm(model, num_images_to_generate, num_timesteps)\n",
    "\n",
    "# Convert generated images from [-1,1] to [0,1] for visualization\n",
    "generated_images = (generated_images + 1) / 2\n",
    "print(\"Generated Images Tensor Shape:\", generated_images.shape)\n",
    "print(\"Min:\", generated_images.min().item(), \"Max:\", generated_images.max().item())\n",
    "\n",
    "# Create figure\n",
    "fig, axes = plt.subplots(1, num_images_to_generate, figsize=(15, 3))\n",
    "\n",
    "for i in range(num_images_to_generate):\n",
    "    img = generated_images[i].cpu().squeeze().numpy()\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()\n",
    "print(\"Generation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
