{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d42497e6-b7b6-488f-95de-dab01e6cccce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing huggingface_hub.file_download: 'Version'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: embed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "# from torchvision import transforms\n",
    "from monai import transforms as mt\n",
    "\n",
    "from data_loaders_l import SynthesisDataModule, NiftiSynthesisDataset\n",
    "from model_architectures import DDPM, UNet, MonaiDDPM \n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "# Load configuration\n",
    "with open('config_l.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "pl.seed_everything(config.get('seed', 42), workers=True)\n",
    "# Extract parameters from config\n",
    "batch_size = config['batch_size']\n",
    "learning_rate = config['learning_rate']\n",
    "num_epochs = config['num_epochs']\n",
    "label_dim = config.get('label_dim', 4)\n",
    "experiment_name = config['experiment_name']\n",
    "model_type = config['model_type']\n",
    "resize_dim = config.get('resize_dim', False) #set false for no resizing\n",
    "# Prepare output directories\n",
    "experiment_path = os.path.join('experiments', experiment_name)\n",
    "os.makedirs(experiment_path, exist_ok=True)\n",
    "# Save a copy of the config for reproducibility\n",
    "with open(os.path.join(experiment_path, 'config.yaml'), 'w') as out_f:\n",
    "    yaml.dump(config, out_f)\n",
    "\n",
    "# Define the root directory\n",
    "root_dir = config['root_dir']\n",
    "data_dir = config['data_dir']\n",
    "full_data_path = os.path.join(root_dir, data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f20c5eb-3522-4d68-8af8-87dc825f6e1b",
   "metadata": {},
   "source": [
    "# Load transforms and the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a663968b-5dd2-4773-9beb-00133166fe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 256, 256]) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_transforms = mt.Compose(\n",
    "    [\n",
    "        mt.LoadImaged(keys=[\"image\"]),\n",
    "        mt.SqueezeDimd(keys=[\"image\"], dim=-1), # (H,W,1) → (H,W)\n",
    "        mt.EnsureChannelFirstd(keys=[\"image\"]), # (1,H,W)\n",
    "        mt.ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        mt.ToTensord(keys=[\"image\"]),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = NiftiSynthesisDataset(full_data_path, transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "img_batch, _ = next(iter(train_loader))\n",
    "print(img_batch.shape, img_batch.min().item(), img_batch.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f1f813-1c7a-48a0-b4df-e2063849d334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 256, 64, 64]) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "train_transforms = mt.Compose(\n",
    "    [\n",
    "        mt.LoadImaged(keys=[\"image\"]),\n",
    "        mt.SqueezeDimd(keys=[\"image\"], dim=-1), # (H,W,1) → (H,W)\n",
    "        mt.Resized(keys=[\"image\"], spatial_size=[64, 64], mode=\"bilinear\"),\n",
    "        mt.EnsureChannelFirstd(keys=[\"image\"]), # (1,H,W)\n",
    "        mt.ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        mt.ToTensord(keys=[\"image\"]),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "dataset = NiftiSynthesisDataset(full_data_path, transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "img_batch, _ = next(iter(train_loader))\n",
    "print(img_batch.shape, img_batch.min().item(), img_batch.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6723372-3572-4640-b564-1f996b7b5c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 64, 64]) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "train_transforms = mt.Compose(\n",
    "    [\n",
    "        mt.LoadImaged(keys=[\"image\"]),\n",
    "        mt.SqueezeDimd(keys=[\"image\"], dim=-1), # (H,W,1) → (H,W)\n",
    "        mt.EnsureChannelFirstd(keys=[\"image\"]), # (1,H,W)\n",
    "        mt.Resized(keys=[\"image\"], spatial_size=[64, 64], mode=\"bilinear\"),\n",
    "        mt.ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=255.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        mt.ToTensord(keys=[\"image\"]),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "dataset = NiftiSynthesisDataset(full_data_path, transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "img_batch, _ = next(iter(train_loader))\n",
    "print(img_batch.shape, img_batch.min().item(), img_batch.max().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aedf56-1da7-4195-9ef6-413950ce5b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(17, 17))\n",
    "for i in range(16):\n",
    "    plt.subplot(9, 9, 1 + i)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(samples[i].squeeze(0).clip(0, 1).data.cpu().numpy(),\n",
    "               cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d812e188-9044-4c09-81f9-af3fa5454036",
   "metadata": {},
   "source": [
    "# Load the model!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4022fe-ac17-4a62-b231-624314846bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MonaiDDPM(lr=learning_rate, T=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248657ac-54a5-41c4-bff2-16050619ba0b",
   "metadata": {},
   "source": [
    "# Set up lightning functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3be08d-9f2d-469a-9fe7-8cb7b80ad4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/locolinux2/miniconda3/envs/U24/lib/python3.9/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in `fast_dev_run` mode: will run the requested loop using 1 batch(es). Logging and checkpointing is suppressed.\n"
     ]
    }
   ],
   "source": [
    "tb_logger = pl_loggers.TensorBoardLogger('logs/', name=experiment_name)\n",
    "\n",
    "# Set up callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=os.path.join(experiment_path, \"checkpoints\"),\n",
    "    filename=f\"{model_type}-{{epoch:02d}}-{{step}}\",\n",
    "    auto_insert_metric_name=True,\n",
    "    save_top_k=1,\n",
    "    monitor=\"train_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"train_loss\",\n",
    "    patience=15,\n",
    "    mode=\"min\",\n",
    "    check_on_train_epoch_end=True,\n",
    ")\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "\n",
    "# Set up Trainer\n",
    "trainer = pl.Trainer(\n",
    "    fast_dev_run=True, #set to true for tests\n",
    "    max_epochs=num_epochs,\n",
    "    accelerator=\"auto\",\n",
    "    precision=16,\n",
    "    logger=tb_logger,\n",
    "    callbacks=[checkpoint_callback, early_stopping, lr_monitor],\n",
    "    enable_progress_bar=True,\n",
    "    num_sanity_val_steps=0,\n",
    "    gradient_clip_val=1.0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a3ebb0-2527-4bce-86ba-0f29ee81d272",
   "metadata": {},
   "source": [
    "# Do the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cbaf76b-a79d-4d3c-9dae-eb10ede6dc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params | Mode \n",
      "---------------------------------------------------------\n",
      "0 | unet      | DiffusionModelUNet | 18.5 M | train\n",
      "1 | scheduler | DDPMScheduler      | 0      | train\n",
      "---------------------------------------------------------\n",
      "18.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "18.5 M    Total params\n",
      "74.004    Total estimated model params size (MB)\n",
      "203       Modules in train mode\n",
      "0         Modules in eval mode\n",
      "/home/locolinux2/miniconda3/envs/U24/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e208c40790314eb6ad74d70c7e913a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloaders=train_loader)\n",
    "# trainer.fit(model, data_module) # train_dataloaders=train_loader)\n",
    "\n",
    "print('Training complete!')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
